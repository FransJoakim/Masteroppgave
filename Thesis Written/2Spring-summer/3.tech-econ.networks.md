
At the university I got engaged in the student council, which shaped my experience profoundly. Leaving this part of the story out would be to miss-represent the way that the theory and empiri emerged. What became apparent was the interest of students in the making of an academic program, and its relationship with pedagogic investments.

The abstract use of numbers and 'data' at the university pose a difficult challenge for students. Not only are their hard to apply in real world settings, in which questions of ethics, relevance and validity intermix. Moreover, very few arenas exist for the application of such methods apart from subsidized classes. Who decides how these methods are integrated with the practical applications of *research media*? Who decides the investments that go into switching the area of competence? These questions are demonstrated well through the question of a switch to the quantitative programing in R. R is a version of what becomes applied on social media platforms and what in academia often becomes described in its general form, as an algorithm. Is this will to abstract for the sake of nuance (?) typical? Knowledge is described on a theoretical level, and is criticized for not applying practical approaches to learning. Learning by doing is situated in the social, and remain bound to group contexts. The same is then happening to the idea of computing, which is approached at the same level as everything else. The 'programing' game remains a game, while the same shift in perspective (that was demonstrated by the game Simen showed) is folded into the number technologies in the R software. Rather 'the digital' is bound to controversies around identity that was solved by social media as curators. The internet is treated as something 'out-there' although Internet bullying remains a massive problem.


The students at UiO have interest in organizing and applying their skill outside of the community of practice that is established at the faculties. An option was to follow this path from the beginning, or otherwise to do a double case study. However, since the secondary school LMS was as a good opportunity for gathering empirical material, and because I was interested studying the decentralized the school system posed as the better option.

What is decentralized about the technology? This caused me a lot of confusion. Several technologies were in use. Some more abstract than others.
These technologies are abstracting, and this way works as boundary objects. They are yet undefined.
I follow the production of some numbers and facts. On the other hand, I also follow the interfaces:
- Numbers like the facts about China and India conflict with the map approach. The example of the tree stands as a unique example that is not replaced by the digital text-book. The picture of the cell survives the scrutiny of both the search engine and questions about DNA (its own molecular scale). The history and nationality of the thong, as well as new (non-physical) instruments are integrated in an inclusive approach to a keyword (an internal search). Objectivity is itself discussed and poses as an interesting starting point for the topic of perspective (though of in terms of life and death, but questioned in terms of an ontology of a human viewer).
- In my case the computer-technician for example does not know about the groups within the cloud network. These groups are discouraged, but also exists outside of the control of teachers or administrators. He is mostly concerned with the computers and the testing out of some functions in the interface (he points to the way the information-board is supposed to work). The teachers on the other hand approach the computer heuristically. A key word is access, which becomes a question. Not so much of method, but of reference and an ontological choreography in which the strength of a the relationship ideally is mediated only by the presence of groups or individuals.
